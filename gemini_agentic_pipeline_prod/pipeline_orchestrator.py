# main_orchestrator.py
import asyncio
import json
from typing import List, Optional, Dict, Any
import os
from datetime import datetime, timezone


from config import BASE_OUTPUT_FOLDER, IMAGE_GENERATION_MODEL  # BASE_OUTPUT_FOLDER can remain if it's a fixed path in the container

from data_models import (
    Layer2Input, PostHistoryEntry, Requirements,
    PlatformAgentInput, PlatformAgentOutput,
    FinalGeneratedPost, SavedMediaAsset,
    TranslatorAgentInput
)
from llm_services import run_layer_2_decision_maker, run_platform_adaptation_agent, run_translator_agent
from media_generation import generate_visual_asset_for_platform
from file_utils import get_filename_base, ensure_platform_folder_exists, save_text_content
from cloud_storage_service import cloud_storage, upload_generated_post_files
from image_control_service import ImageControlProcessor
from api_models import ContentGeneratorData


# This function will now take all dynamic parameters
async def generate_social_media_posts_pipeline(
    subject: str,
    company_name: str,
    company_mission: str,
    company_sentiment: str,
    language: str,
    platforms_post_types_map: List[Dict[str, str]], # This is now a parameter
    tone: str, # Assuming TONE was also a global, make it a param
    requirements: Optional[Requirements] = None,
    posts_history: Optional[List[PostHistoryEntry]] = None,
    upload_to_cloud: bool = True,
    image_generation_model: Optional[str] = None,  # Optional: custom model from frontend
) -> Dict[str, any]:
    """
    Generate social media posts, translate if necessary, and optionally upload to cloud storage.
    """
    print("üöÄ Starting Social Media Post Generation Pipeline üöÄ")

    # --- Determine image generation model to use ---
    model_to_use = image_generation_model if image_generation_model else IMAGE_GENERATION_MODEL
    print(f"üé® Using image generation model: {model_to_use}")

    # --- Derive target platforms from the map ---
    platform_configs: Dict[str, str] = {}
    for entry in platforms_post_types_map:
        if isinstance(entry, dict) and len(entry) == 1:
            platform_name, post_type = list(entry.items())[0]
            platform_configs[platform_name] = post_type
        else:
            print(f"‚ö†Ô∏è Warning: Invalid entry in platforms_post_types_map: {entry}. Skipping.")
            continue

    if not platform_configs:
        error_msg = "No valid platforms configured in platforms_post_types_map."
        print(f"üö´ Error: {error_msg} Aborting.")
        return {
            "error": error_msg,
            "pipeline_id": f"{get_filename_base(subject)}_error_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}",
            "subject": subject,
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "posts": [],
            "cloud_uploads": []
        }

    # --- Generate Filename Base ---
    filename_base = get_filename_base(subject)
    print(f"üé¨ Using filename base: {filename_base}")

    target_platforms_from_map = list(platform_configs.keys())
    print(f"üó∫Ô∏è Targeting platforms based on PLATFORMS_POST_TYPES_MAP: {', '.join(target_platforms_from_map)}")

    # Determine a general post type hint for Layer 2
    layer2_platform_post_type_hint = "General content"  # Default
    if platform_configs:
        unique_post_types = sorted(list(set(p_type for p_type in platform_configs.values() if p_type)))
        if unique_post_types:
            layer2_platform_post_type_hint = f"Content adaptable for {', '.join(unique_post_types)} posts"
        else:
            layer2_platform_post_type_hint = "General content for various platforms"

    # --- Layer 2: Core Text Generation ---
    layer2_input_data = Layer2Input(
        company_name=company_name,
        company_mission=company_mission,
        company_sentiment=company_sentiment,
        subject=subject,
        platforms_to_target=target_platforms_from_map,
        requirements=requirements,
        posts_history=posts_history,
        language=language,  # L2 gets target lang for context, but generates English
        tone=tone,
        platform_post_type=layer2_platform_post_type_hint  # Added this field
    )
    layer2_result = await run_layer_2_decision_maker(layer2_input_data)
    core_post_text = layer2_result["core_post_text"]
    print(f"üìù Core post text generated by Layer 2: '{core_post_text[:100]}...'")

    # --- Layer 3: Platform Adaptation ---
    platform_adaptation_tasks = []
    for platform_name, platform_post_type_from_map in platform_configs.items():
        print(f"‚öôÔ∏è Preparing adaptation for {platform_name} with post type: {platform_post_type_from_map}")
        platform_agent_input = PlatformAgentInput(
            company_name=company_name,
            company_mission=company_mission,
            company_sentiment=company_sentiment,
            language=language,  # Pass target language for context
            tone=tone,
            subject=subject,
            platform_post_type=platform_post_type_from_map,
            core_post_text_suggestion=core_post_text,
            target_platform=platform_name
        )
        platform_adaptation_tasks.append(
            (platform_name, platform_post_type_from_map, run_platform_adaptation_agent(platform_agent_input))
        )

    platform_agent_results_gathered = await asyncio.gather(*(task for _, _, task in platform_adaptation_tasks))

    platform_outputs_map: Dict[str, PlatformAgentOutput] = {}
    platform_post_types_used: Dict[str, str] = {}

    # First, store all platform adaptation results WITHOUT translation
    for i, platform_result_from_gather in enumerate(platform_agent_results_gathered):
        platform_name = platform_adaptation_tasks[i][0]
        platform_post_type_config_for_platform = platform_adaptation_tasks[i][1]

        # Make a mutable copy if needed, or ensure PlatformAgentOutput is a dict
        current_platform_output: PlatformAgentOutput = platform_result_from_gather

        platform_outputs_map[platform_name] = current_platform_output
        platform_post_types_used[platform_name] = platform_post_type_config_for_platform

    # --- FINAL TRANSLATION LAYER ---
    # Translation happens AFTER all platform adaptations are complete
    if language.lower() != "english" and language.lower() != "en":  # More robust check
        print(f"\nüåç TRANSLATION LAYER: Translating all content from English to {language}...")
        translation_tasks = []
        platform_names_for_translation = []

        for platform_name, current_platform_output in platform_outputs_map.items():
            original_english_text = current_platform_output["platform_specific_text"]
            print(f"  üåç Preparing translation for {platform_name}...")

            translator_input = TranslatorAgentInput(
                text_to_translate=original_english_text,
                target_language=language,
                company_name=company_name,
                company_mission=company_mission,
                original_subject=subject
            )
            translation_tasks.append(run_translator_agent(translator_input))
            platform_names_for_translation.append(platform_name)

        # Execute all translations in parallel
        translation_results = await asyncio.gather(*translation_tasks, return_exceptions=True)

        # Apply translations to platform outputs
        for i, translation_result in enumerate(translation_results):
            platform_name = platform_names_for_translation[i]
            if isinstance(translation_result, Exception):
                print(f"  üö® Error translating content for {platform_name}: {translation_result}. Using original English text.")
            else:
                platform_outputs_map[platform_name]["platform_specific_text"] = translation_result["translated_text"]
                print(f"  ‚úÖ Translation successful for {platform_name}.")

        print(f"‚úÖ TRANSLATION LAYER COMPLETE: Translated {len(platform_names_for_translation)} platforms.")

    # --- Media Generation (if applicable, per platform) ---
    final_posts_results: List[FinalGeneratedPost] = []
    media_generation_coroutines = []
    platforms_needing_media_info: List[tuple[str, str, str]] = []

    for platform_name, platform_output_data in platform_outputs_map.items():  # Changed variable name
        current_platform_post_type_from_config = platform_post_types_used[platform_name]

        if current_platform_post_type_from_config in ["Image", "Video"]:
            media_prompt = platform_output_data.get("platform_media_generation_prompt")
            if media_prompt:
                platform_dir = ensure_platform_folder_exists(BASE_OUTPUT_FOLDER, platform_name)
                media_type_to_generate = "image" if current_platform_post_type_from_config == "Image" else "video"

                print(
                    f"üñºÔ∏è Scheduling {media_type_to_generate} generation for {platform_name} (Prompt: '{media_prompt[:50]}...')")
                media_generation_coroutines.append(
                    generate_visual_asset_for_platform(
                        image_prompt=media_prompt,
                        output_directory=platform_dir,
                        filename_base=filename_base,
                        media_type=media_type_to_generate,
                        model=model_to_use  # Use model from frontend or config default
                    )
                )
                platforms_needing_media_info.append((platform_name, media_prompt, media_type_to_generate))
            else:
                print(
                    f"‚ÑπÔ∏è Info: Platform agent for {platform_name} (type: {current_platform_post_type_from_config}) did not provide a media prompt.")
        else:
            print(
                f"‚ÑπÔ∏è Info: Platform {platform_name} is Text-only (type: {current_platform_post_type_from_config}). No media generation needed.")

    generated_media_paths: List[Optional[str]] = []
    if media_generation_coroutines:
        print(f"\n‚è≥ Starting {len(media_generation_coroutines)} media generation tasks...")
        try:
            results_or_exceptions = await asyncio.gather(*media_generation_coroutines, return_exceptions=True)
            for i, res_or_exc in enumerate(results_or_exceptions):
                platform_name_for_media, _, _ = platforms_needing_media_info[i]
                if isinstance(res_or_exc, Exception):
                    print(f"üö® Error generating media for {platform_name_for_media}: {res_or_exc}")
                    generated_media_paths.append(None)
                else:
                    generated_media_paths.append(res_or_exc)
        except Exception as e:
            print(f"üö® Major error during media generation gathering: {e}")
            generated_media_paths = [None] * len(platforms_needing_media_info)

    # --- Cloud Upload Tasks (Prepare) ---
    cloud_upload_tasks = []
    cloud_upload_results_list: List[Dict[str, Any]] = []

    # --- Assemble Final Posts and Prepare Cloud Uploads ---
    media_path_idx = 0
    for platform_name in target_platforms_from_map:
        platform_output_data = platform_outputs_map.get(platform_name)  # Changed variable name
        if not platform_output_data:
            print(f"‚ö†Ô∏è Warning: No platform output for {platform_name} during final assembly. Skipping.")
            continue

        platform_dir = ensure_platform_folder_exists(BASE_OUTPUT_FOLDER, platform_name)
        # Text content is now potentially translated
        text_content = platform_output_data["platform_specific_text"]
        text_file_path = save_text_content(platform_dir, filename_base, text_content)

        current_media_asset: Optional[SavedMediaAsset] = None
        media_prompt_used_for_this_platform: Optional[str] = None
        media_file_path: Optional[str] = None
        # actual_media_type_generated: Optional[str] = None # Not used later, can remove if not needed for debugging

        media_info_for_platform = next((info for info in platforms_needing_media_info if info[0] == platform_name),
                                       None)

        if media_info_for_platform:
            original_prompt_for_platform = media_info_for_platform[1]
            requested_media_type = media_info_for_platform[2]

            if media_path_idx < len(generated_media_paths):
                path_or_none = generated_media_paths[media_path_idx]
                if path_or_none:
                    media_file_path = path_or_none
                    current_media_asset = SavedMediaAsset(
                        type=requested_media_type,
                        file_path=media_file_path
                    )
                    media_prompt_used_for_this_platform = original_prompt_for_platform
                    # actual_media_type_generated = requested_media_type
                else:
                    print(f"‚ö†Ô∏è Media generation failed or skipped for {platform_name}. No media asset will be linked.")
                media_path_idx += 1
            else:
                print(f"üîç Warning: Mismatch in media paths and platforms needing media for {platform_name}.")

        if upload_to_cloud:
            cloud_upload_task = upload_generated_post_files(
                filename_base=filename_base,
                platform=platform_name,
                text_content=text_content,  # Uses potentially translated text
                media_file_path=media_file_path,
                media_generation_prompt=media_prompt_used_for_this_platform
            )
            cloud_upload_tasks.append((platform_name, cloud_upload_task))

        final_posts_results.append(FinalGeneratedPost(
            platform=platform_name,
            post_type=platform_post_types_used[platform_name],
            text_file_path=text_file_path,
            media_asset=current_media_asset,
            original_text_content=text_content,  # This will store the final (potentially translated) text
            media_generation_prompt_used=media_prompt_used_for_this_platform
        ))

    # --- Execute Cloud Uploads Concurrently ---
    if upload_to_cloud and cloud_upload_tasks:
        print(f"\n‚òÅÔ∏è Starting {len(cloud_upload_tasks)} cloud upload tasks...")
        try:
            cloud_upload_results_tuples = await asyncio.gather(*(task for _, task in cloud_upload_tasks))
            for i, upload_result in enumerate(cloud_upload_results_tuples):
                platform_name_for_upload = cloud_upload_tasks[i][0]  # Renamed for clarity
                cloud_upload_results_list.append({
                    "platform": platform_name_for_upload,
                    "upload_result": upload_result
                })
                for post in final_posts_results:
                    if post["platform"] == platform_name_for_upload:
                        post["cloud_storage"] = upload_result  # type: ignore
                        break
        except Exception as e:
            print(f"üö® Error during cloud uploads: {e}")

    # --- Create and Upload Summary ---
    pipeline_summary = {
        "pipeline_id": f"{filename_base}_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}",
        "subject": subject,
        "platform_configurations": platform_configs,
        "language_used": language,  # Reports the target language
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "posts": final_posts_results,
        "cloud_uploads_summary": cloud_upload_results_list,
        "requirements": requirements,
        "posts_history": posts_history
    }

    summary_filename = os.path.join(BASE_OUTPUT_FOLDER, f"{filename_base}_summary.json")
    try:
        with open(summary_filename, "w", encoding='utf-8') as f:
            json.dump(pipeline_summary, f, indent=4, ensure_ascii=False)
        print(f"üìã Local summary saved to {summary_filename}")
    except IOError as e:
        print(f"üö® Error saving local summary: {e}")

    if upload_to_cloud:
        try:
            summary_cloud_path = cloud_storage.generate_cloud_path(
                filename_base, "summary", "metadata", "json"
            )
            summary_upload_result = await cloud_storage.upload_json_data(
                pipeline_summary,
                summary_cloud_path,
                metadata={
                    "content_type": "pipeline_summary",
                    "subject": subject,
                    "platforms_configured_count": str(len(platform_configs)),
                    "language": language
                }
            )
            pipeline_summary["summary_cloud_storage"] = summary_upload_result  # type: ignore
            print(f"‚òÅÔ∏è Summary uploaded to cloud: {summary_upload_result.get('public_url', 'URL not available')}")
        except Exception as e:
            print(f"üö® Error uploading summary to cloud: {e}")

    print("\n‚úÖ Social Media Post Generation Pipeline Complete! ‚úÖ")
    return pipeline_summary


async def main():
    """Main function with enhanced cloud integration."""

    sample_posts_history: List[PostHistoryEntry] = [
        {"post_type": "A", "count": 7, "score": 8},
        {"post_type": "B", "count": 5, "score": 9},
        {"post_type": "C", "count": 3, "score": 7}
    ]

    # The orchestrator now uses PLATFORMS_POST_TYPES_MAP from config.py
    # So, target_platforms argument is removed from generate_social_media_posts_pipeline call
    pipeline_result = await generate_social_media_posts_pipeline(
        posts_history=sample_posts_history,
        upload_to_cloud=True
    )

    print("\n" + "=" * 60)
    print("DODOOOOOOOOOOOOOOOOOOOOOOOOOOOOO üìä PIPELINE EXECUTION SUMMARY")
    print("=" * 60)

    print(f"Pipeline ID: {pipeline_result['pipeline_id']}")
    print(f"Subject: {pipeline_result['subject']}")
    # print(f"Post Type: {pipeline_result['post_type']}") # Removed global post type
    print(f"Language: {pipeline_result.get('language_used', 'N/A')}")
    print(f"Platform Configurations: {json.dumps(pipeline_result.get('platform_configurations'))}")
    print(f"Generated At: {pipeline_result['generated_at']}")

    print(f"\nüì± GENERATED POSTS ({len(pipeline_result['posts'])} total):")
    for i, post_info in enumerate(pipeline_result['posts']):
        print(f"\n--- Post {i + 1}: {post_info['platform'].upper()} (Type: {post_info['post_type']}) ---")
        print(f"Text Preview: {post_info['original_text_content'][:100]}...")

        if post_info.get('media_asset'):
            media_asset = post_info['media_asset']
            print(f"Media: {media_asset['type']} - {media_asset['file_path']}")  # type: ignore
            if post_info.get('media_generation_prompt_used'):
                print(f"Media Prompt: {post_info['media_generation_prompt_used'][:70]}...")

        if post_info.get('cloud_storage'):
            cloud_info = post_info['cloud_storage']
            print(f"‚òÅÔ∏è Cloud Storage:")
            if isinstance(cloud_info, dict) and 'uploads' in cloud_info:  # Check structure
                for upload in cloud_info.get('uploads', []):
                    if isinstance(upload, dict) and upload.get('success'):  # Check structure
                        print(f"  ‚úÖ {upload.get('cloud_path', 'Unknown path')}")
                        print(f"     URL: {upload.get('public_url', 'URL not available')}")
                    elif isinstance(upload, dict):
                        print(f"  ‚ùå Upload failed: {upload.get('error', 'Unknown error')}")
                    else:
                        print(f"  ‚ùì Unknown cloud upload item format: {upload}")
            else:
                print(f"  ‚ùì Cloud storage info format unexpected: {cloud_info}")

    if pipeline_result.get('summary_cloud_storage'):
        summary_cloud = pipeline_result['summary_cloud_storage']
        if isinstance(summary_cloud, dict) and summary_cloud.get('success'):  # Check structure
            print(f"\nüìã Summary Cloud Storage:")
            print(f"  ‚úÖ {summary_cloud.get('public_url', 'URL not available')}")
        elif isinstance(summary_cloud, dict):
            print(f"  ‚ùå Summary upload failed: {summary_cloud.get('error', 'Unknown error')}")
        else:
            print(f"  ‚ùì Summary cloud storage info format unexpected: {summary_cloud}")

    print(f"\nüåê WEB APP INTEGRATION:")
    print(f"Your Vite/TSX web app can now retrieve all generated content from:")
    print(f"- Individual post files via their public URLs")
    print(f"- Complete pipeline summary via the summary JSON URL")
    print(f"- Use the pipeline_id '{pipeline_result['pipeline_id']}' to track this generation")

    print("\nüèÅ All operations completed!")


async def generate_enhanced_social_media_posts_pipeline(
    request_data: ContentGeneratorData
) -> Dict[str, Any]:
    """
    Enhanced pipeline that processes the new ContentGeneratorData structure with image controls.
    Supports hierarchical image control (Level 1 global, Level 2 platform-specific).
    """
    print("üöÄ Starting Enhanced Social Media Post Generation Pipeline üöÄ")

    # Extract data from the new structure
    company = request_data.company
    content = request_data.content
    image_control = request_data.image_control
    platforms = request_data.platforms

    # --- Determine image generation model to use ---
    model_to_use = request_data.image_generation_model if request_data.image_generation_model else IMAGE_GENERATION_MODEL
    print(f"üé® Using image generation model: {model_to_use}")

    # Filter selected platforms
    selected_platforms = [p for p in platforms if p.selected]
    if not selected_platforms:
        error_msg = "No platforms selected for content generation."
        print(f"üö´ Error: {error_msg}")
        return {
            "error": error_msg,
            "pipeline_id": f"{get_filename_base(content.topic)}_error_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}",
            "subject": content.topic,
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "posts": [],
            "cloud_uploads": []
        }
    
    # Convert to the format expected by the existing pipeline
    platforms_post_types_map = [
        {platform.platform: platform.post_type} for platform in selected_platforms
    ]
    
    # Create filename base from topic
    filename_base = get_filename_base(content.topic)
    print(f"üé¨ Using filename base: {filename_base}")
    
    # Prepare company colors for image enhancement
    company_colors = {
        "primary_color_1": company.primary_color_1,
        "primary_color_2": company.primary_color_2
    }
    
    # --- Layer 2: Core Text Generation (using existing structure) ---
    target_platforms = [p.platform for p in selected_platforms]
    layer2_input_data = Layer2Input(
        company_name=company.name,
        company_mission=company.mission,
        company_sentiment=company.tone_of_voice,  # Use tone_of_voice from company
        subject=content.topic,
        platforms_to_target=target_platforms,
        requirements=None,  # Could be derived from content.description if needed
        posts_history=None,  # Not provided in new structure
        language=request_data.language,
        tone=company.tone_of_voice,
        platform_post_type="Enhanced content with image controls"
    )
    
    layer2_result = await run_layer_2_decision_maker(layer2_input_data)
    core_post_text = layer2_result["core_post_text"]
    print(f"üìù Core post text generated: '{core_post_text[:100]}...'")
    
    # --- Enhanced Platform Adaptation with Image Controls ---
    platform_outputs_map = {}
    platforms_needing_media_info = []

    for platform in selected_platforms:
        platform_name = platform.platform
        print(f"‚öôÔ∏è Processing enhanced adaptation for {platform_name}")

        # STEP 1: DETERMINE EFFECTIVE IMAGE CONTROL (if-else logic)
        # This pre-processes which level applies BEFORE calling the LLM
        effective_control = None
        control_level_used = "none"

        # Check Level 2 (platform-specific) first
        level_2 = image_control.level_2
        platform_level_2 = None
        if level_2:
            platform_level_2 = getattr(level_2, platform_name, None)

        if platform_level_2 and platform_level_2.enabled:
            # USE LEVEL 2 - Platform-specific override
            effective_control = ImageControlProcessor.resolve_effective_image_control(
                image_control, platform_name
            )
            control_level_used = "level_2"
            print(f"  ‚úì Using Level 2 (platform-specific) image control for {platform_name}")
        elif image_control.level_1.enabled:
            # USE LEVEL 1 - Global settings
            effective_control = ImageControlProcessor.resolve_effective_image_control(
                image_control, platform_name
            )
            control_level_used = "level_1"
            print(f"  ‚úì Using Level 1 (global) image control for {platform_name}")
        else:
            # NO IMAGE CONTROL - AI decides everything
            control_level_used = "none"
            print(f"  ‚óã No image control applied for {platform_name} - AI will use defaults")

        # STEP 2: DOWNLOAD STARTING IMAGE IF PROVIDED
        starting_image_path = None
        if effective_control and effective_control.starting_image_url:
            platform_dir = ensure_platform_folder_exists(BASE_OUTPUT_FOLDER, platform_name)
            starting_image_path = await ImageControlProcessor.download_starting_image(
                effective_control.starting_image_url,
                platform_dir,
                filename_base
            )
            if starting_image_path:
                effective_control.starting_image_path = starting_image_path
                print(f"  ‚úì Downloaded starting image for {platform_name}")

        # STEP 3: BUILD CLEAR, SPECIFIC IMAGE INSTRUCTIONS FOR LLM
        # Instead of making the LLM decide, we tell it EXACTLY what to do
        image_generation_instructions = None
        if effective_control and effective_control.enabled and platform.post_type in ["Image", "Video"]:
            instructions_parts = []

            # CRITICAL: Explicitly instruct NO text/captions in the image
            instructions_parts.append("IMPORTANT: Create a clean visual design without any text, captions, labels, or written words in the image")

            # Style instruction
            if effective_control.style:
                instructions_parts.append(f"Visual style: {effective_control.style}")

            # Visual guidance
            if effective_control.guidance:
                instructions_parts.append(f"Creative direction: {effective_control.guidance}")

            # Aspect ratio - Valid values: "1:1", "3:4", "4:3", "9:16", "16:9"
            if effective_control.ratio:
                instructions_parts.append(f"Compose for {effective_control.ratio} aspect ratio")

            # Brand colors - use natural language instead of hex codes
            # Convert technical color specs to descriptive language to prevent rendering as text
            color_desc_parts = []
            if company.primary_color_1:
                if company.primary_color_1.startswith('#'):
                    color_desc_parts.append("incorporate the brand's primary color palette")
                else:
                    color_desc_parts.append(f"feature {company.primary_color_1} tones")

            if company.primary_color_2:
                if company.primary_color_2.startswith('#'):
                    color_desc_parts.append("with complementary brand accent colors")
                else:
                    color_desc_parts.append(f"with {company.primary_color_2} accents")

            if color_desc_parts:
                instructions_parts.append(f"Color palette: {' '.join(color_desc_parts)}")

            # Starting image context
            if starting_image_path:
                instructions_parts.append(f"Use starting image as compositional base")

            # Combine into clear instructions
            image_generation_instructions = ". ".join(instructions_parts)
            print(f"  ‚úì Image instructions for {platform_name}: {image_generation_instructions[:100]}...")

        # STEP 4: RUN PLATFORM ADAPTATION WITH CLEAR INSTRUCTIONS
        platform_agent_input = PlatformAgentInput(
            company_name=company.name,
            company_mission=company.mission,
            company_sentiment=company.tone_of_voice,
            subject=content.topic,
            core_post_text_suggestion=core_post_text,
            target_platform=platform_name,
            platform_post_type=platform.post_type,
            language=request_data.language,
            tone=company.tone_of_voice
        )

        platform_result = await run_platform_adaptation_agent(platform_agent_input)

        # STEP 5: SANITIZE AND ENHANCE MEDIA PROMPT WITH PRE-DETERMINED INSTRUCTIONS
        # First sanitize to remove instruction-like text that could be misinterpreted as overlay text
        # Then append our clear instructions to the LLM's base prompt
        original_media_prompt = platform_result.get("platform_media_generation_prompt")
        if original_media_prompt:
            # Sanitize the LLM-generated prompt to remove problematic instruction phrases
            sanitized_prompt = ImageControlProcessor.sanitize_prompt_for_image_generation(original_media_prompt)

            if image_generation_instructions:
                # Append our clear instructions to the sanitized base prompt
                enhanced_prompt = f"{sanitized_prompt}. {image_generation_instructions}"
                platform_result["platform_media_generation_prompt"] = enhanced_prompt
                print(f"  ‚úì Sanitized and enhanced media prompt for {platform_name} with {control_level_used} controls")
            else:
                # Even without image controls, use the sanitized prompt
                platform_result["platform_media_generation_prompt"] = sanitized_prompt
                print(f"  ‚úì Sanitized media prompt for {platform_name} (no image controls)")

        # Store platform result WITHOUT translation (translation happens later as final layer)
        platform_outputs_map[platform_name] = platform_result

        # STEP 6: TRACK PLATFORMS NEEDING MEDIA
        if original_media_prompt:
            media_type = "video" if platform.post_type == "Video" else "image"
            platforms_needing_media_info.append((
                platform_name,
                platform_result["platform_media_generation_prompt"],
                media_type,
                effective_control  # Pass the effective control for generation config
            ))

    # --- FINAL TRANSLATION LAYER ---
    # Translation happens AFTER all platform adaptations are complete, BEFORE media generation
    if request_data.language.lower() not in ["english", "en"]:
        print(f"\nüåç TRANSLATION LAYER: Translating all content from English to {request_data.language}...")
        translation_tasks = []
        platform_names_for_translation = []

        for platform_name, platform_result in platform_outputs_map.items():
            original_english_text = platform_result["platform_specific_text"]
            print(f"  üåç Preparing translation for {platform_name}...")

            translator_input = TranslatorAgentInput(
                text_to_translate=original_english_text,
                target_language=request_data.language,
                company_name=company.name,
                company_mission=company.mission,
                original_subject=content.topic
            )
            translation_tasks.append(run_translator_agent(translator_input))
            platform_names_for_translation.append(platform_name)

        # Execute all translations in parallel
        translation_results = await asyncio.gather(*translation_tasks, return_exceptions=True)

        # Apply translations to platform outputs
        for i, translation_result in enumerate(translation_results):
            platform_name = platform_names_for_translation[i]
            if isinstance(translation_result, Exception):
                print(f"  üö® Error translating content for {platform_name}: {translation_result}. Using original English text.")
            else:
                platform_outputs_map[platform_name]["platform_specific_text"] = translation_result["translated_text"]
                print(f"  ‚úÖ Translation successful for {platform_name}.")

        print(f"‚úÖ TRANSLATION LAYER COMPLETE: Translated {len(platform_names_for_translation)} platforms.")

    # --- Enhanced Media Generation ---
    generated_media_paths = []
    if platforms_needing_media_info:
        print(f"\nüé® Generating {len(platforms_needing_media_info)} enhanced media assets...")

        media_generation_tasks = []
        for platform_name, enhanced_prompt, media_type, effective_control in platforms_needing_media_info:
            platform_dir = ensure_platform_folder_exists(BASE_OUTPUT_FOLDER, platform_name)

            # Generate config for image generation using the pre-determined effective control
            image_config = {}
            if effective_control:
                image_config = ImageControlProcessor.get_image_generation_config(effective_control)
                print(f"  ‚úì Using image config for {platform_name}: {image_config}")

            # The enhanced_prompt already contains all the clear instructions
            # Now just generate the media with those instructions
            task = generate_visual_asset_for_platform(
                image_prompt=enhanced_prompt,
                output_directory=platform_dir,
                filename_base=filename_base,
                media_type=media_type,
                image_config=image_config,  # Pass the generated config
                model=model_to_use  # Use model from frontend or config default
            )
            media_generation_tasks.append(task)

        try:
            generated_media_paths = await asyncio.gather(*media_generation_tasks, return_exceptions=True)
            successful_count = len([p for p in generated_media_paths if p and not isinstance(p, Exception)])
            print(f"‚úÖ Generated {successful_count}/{len(platforms_needing_media_info)} media assets successfully")
        except Exception as e:
            print(f"üö® Error during media generation: {e}")
            generated_media_paths = [None] * len(platforms_needing_media_info)
    
    # --- Assembly and Cloud Upload (similar to existing pipeline) ---
    final_posts_results = []
    cloud_upload_tasks = []
    cloud_upload_results_list = []
    
    media_path_idx = 0
    for platform in selected_platforms:
        platform_name = platform.platform
        platform_output_data = platform_outputs_map.get(platform_name)
        if not platform_output_data:
            continue
        
        platform_dir = ensure_platform_folder_exists(BASE_OUTPUT_FOLDER, platform_name)
        text_content = platform_output_data["platform_specific_text"]
        
        # Add hashtags and CTA to text content
        enhanced_text = text_content
        if content.hashtags:
            enhanced_text += f"\n\n{' '.join(['#' + tag for tag in content.hashtags])}"
        if content.call_to_action:
            enhanced_text += f"\n\n{content.call_to_action}"
        
        text_file_path = save_text_content(platform_dir, filename_base, enhanced_text)
        
        # Handle media assets
        current_media_asset = None
        media_prompt_used = None
        media_file_path = None
        
        media_info = next((info for info in platforms_needing_media_info if info[0] == platform_name), None)
        if media_info and media_path_idx < len(generated_media_paths):
            path_or_none = generated_media_paths[media_path_idx]
            # Handle both successful paths and exceptions from gather
            if path_or_none and not isinstance(path_or_none, Exception):
                media_file_path = path_or_none
                # media_info is now (platform_name, prompt, media_type, effective_control)
                media_type_used = media_info[2]  # Get media_type from tuple
                current_media_asset = SavedMediaAsset(
                    type=media_type_used,
                    file_path=media_file_path
                )
                media_prompt_used = media_info[1]
            elif isinstance(path_or_none, Exception):
                print(f"  ‚ö†Ô∏è Media generation failed for {platform_name}: {path_or_none}")
            media_path_idx += 1
        
        # Cloud upload
        if request_data.upload_to_cloud:
            cloud_upload_task = upload_generated_post_files(
                filename_base=filename_base,
                platform=platform_name,
                text_content=enhanced_text,
                media_file_path=media_file_path,
                media_generation_prompt=media_prompt_used
            )
            cloud_upload_tasks.append((platform_name, cloud_upload_task))
        
        final_posts_results.append(FinalGeneratedPost(
            platform=platform_name,
            post_type=platform.post_type,
            text_file_path=text_file_path,
            media_asset=current_media_asset,
            original_text_content=enhanced_text,
            media_generation_prompt_used=media_prompt_used
        ))
    
    # Execute cloud uploads
    if request_data.upload_to_cloud and cloud_upload_tasks:
        print(f"\n‚òÅÔ∏è Starting {len(cloud_upload_tasks)} cloud upload tasks...")
        try:
            cloud_upload_results_tuples = await asyncio.gather(*(task for _, task in cloud_upload_tasks))
            for i, upload_result in enumerate(cloud_upload_results_tuples):
                platform_name_for_upload = cloud_upload_tasks[i][0]
                cloud_upload_results_list.append({
                    "platform": platform_name_for_upload,
                    "upload_result": upload_result
                })
                for post in final_posts_results:
                    if post["platform"] == platform_name_for_upload:
                        post["cloud_storage"] = upload_result
                        break
        except Exception as e:
            print(f"üö® Error during cloud uploads: {e}")
    
    # Create summary
    pipeline_summary = {
        "pipeline_id": f"{filename_base}_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}",
        "subject": content.topic,
        "company_info": {
            "name": company.name,
            "mission": company.mission,
            "tone_of_voice": company.tone_of_voice
        },
        "content_details": {
            "topic": content.topic,
            "description": content.description,
            "hashtags": content.hashtags,
            "call_to_action": content.call_to_action
        },
        "image_controls_used": {
            "level_1_enabled": image_control.level_1.enabled,
            "level_2_overrides": len([p for p in [
                image_control.level_2.facebook,
                image_control.level_2.instagram,
                image_control.level_2.linkedin,
                image_control.level_2.twitter
            ] if p and p.enabled])
        },
        "language_used": request_data.language,
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "posts": final_posts_results,
        "cloud_uploads_summary": cloud_upload_results_list
    }
    
    # Save and upload summary
    summary_filename = os.path.join(BASE_OUTPUT_FOLDER, f"{filename_base}_enhanced_summary.json")
    try:
        with open(summary_filename, "w", encoding='utf-8') as f:
            json.dump(pipeline_summary, f, indent=4, ensure_ascii=False)
        print(f"üìã Enhanced summary saved to {summary_filename}")
    except IOError as e:
        print(f"üö® Error saving enhanced summary: {e}")
    
    if request_data.upload_to_cloud:
        try:
            summary_cloud_path = cloud_storage.generate_cloud_path(
                filename_base, "enhanced_summary", "metadata", "json"
            )
            summary_upload_result = await cloud_storage.upload_json_data(
                pipeline_summary,
                summary_cloud_path,
                metadata={
                    "content_type": "enhanced_pipeline_summary",
                    "subject": content.topic,
                    "company": company.name,
                    "platforms_count": str(len(selected_platforms)),
                    "language": request_data.language
                }
            )
            pipeline_summary["summary_cloud_storage"] = summary_upload_result
            print(f"‚òÅÔ∏è Enhanced summary uploaded to cloud: {summary_upload_result.get('public_url', 'URL not available')}")
        except Exception as e:
            print(f"üö® Error uploading enhanced summary to cloud: {e}")
    
    print("\n‚úÖ Enhanced Social Media Post Generation Pipeline Complete! ‚úÖ")
    return pipeline_summary


if __name__ == "__main__":
    asyncio.run(main())

